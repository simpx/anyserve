# Pipeline Example

This example demonstrates how to build a multi-stage processing pipeline using AnyServe's `context.call()` API.

## Architecture

```
                         ┌──────────────────┐
                         │   API Server     │
                         │   :8080          │
                         └────────┬─────────┘
                                  │
              ┌───────────────────┼───────────────────┐
              │                   │                   │
         ┌────▼────┐         ┌────▼────┐         ┌────▼────┐
         │Worker A │ ─────>  │Worker B │ ─────>  │Worker C │
         │ :50051  │ context │ :50052  │ context │ :50053  │
         │tokenize │  .call  │ analyze │  .call  │ format  │
         └─────────┘         └─────────┘         └─────────┘
```

**Data Flow**: Client -> tokenize -> analyze -> format -> Response

## Pipeline Stages

| Stage | Worker | Port | Capability | Input Types | Function |
|-------|--------|------|------------|-------------|----------|
| 1 | Worker A | 50051 | `tokenize` | BYTES (text) | Tokenize text, call analyze |
| 2 | Worker B | 50052 | `analyze` | BYTES + INT32 | Statistical analysis, call format |
| 3 | Worker C | 50053 | `format` | BYTES (JSON) + FP32 + INT32 | Format output report |

## Key Feature: context.call()

The `context.call()` method enables workers to call other capabilities:

```python
@app.capability(type="tokenize")
def handler(request: ModelInferRequest, context: Context) -> ModelInferResponse:
    # Process input
    text = request.get_input("text").bytes_contents[0].decode()
    tokens = tokenize(text)

    # Call another capability via context.call()
    result = context.call(
        model_name="analyze",           # Required: model name
        capability={"type": "analyze"}, # For routing via API Server
        inputs={
            "tokens": [",".join(tokens)],  # BYTES
            "token_count": [len(tokens)],  # INT32
        }
    )

    return build_response(result)
```

### context.call() Parameters

| Parameter | Required | Description |
|-----------|----------|-------------|
| `model_name` | Yes | Name of the model to call |
| `inputs` | Yes | Input data dictionary |
| `capability` | No | Capability query for routing (e.g., `{"type": "analyze"}`) |
| `endpoint` | No | Direct endpoint (e.g., `"localhost:50052"`) |

### Routing Priority

1. If `endpoint` specified → send directly to that endpoint
2. If `capability` specified → discover via API Server
3. Only `model_name` → MVP not supported (raises error)

## Input Types Demonstrated

This example shows different input types:

- **BYTES**: Text strings, JSON data
- **INT32**: Token counts, statistics
- **FP32**: Averages, ratios

## Running the Example

```bash
# Terminal 1: Start all services
./examples/pipeline/run_server.sh

# Terminal 2: Run the test client
./examples/pipeline/run_client.sh
```

### Verify registration

```bash
curl http://localhost:8080/registry | jq
```

You should see all three workers registered with their capabilities.

### Expected Output

```
==============================================================
PIPELINE RESULT:
==============================================================
==================================================
         TEXT ANALYSIS REPORT
==================================================

INPUT TEXT PREVIEW:
  "The quick brown fox jumps over the lazy dog..."

STATISTICS:
  Total tokens:     42
  Unique tokens:    28
  Avg token length: 4.12 characters
  Vocabulary ratio: 66.7%

TOP 5 MOST FREQUENT TOKENS:
  1. 'the' (4x) ####
  2. 'is' (3x) ###
  3. 'fox' (2x) ##
  4. 'quick' (2x) ##
  5. 'lazy' (2x) ##

==================================================
Report generated by AnyServe Pipeline
==================================================
```

## Files

| File | Description |
|------|-------------|
| `worker_a.py` | Tokenize stage - entry point |
| `worker_b.py` | Analyze stage - statistical analysis |
| `worker_c.py` | Format stage - report generation |
| `test_client.py` | Test client demonstrating the pipeline |
| `run_server.sh` | Script to start all services |
| `run_client.sh` | Script to run the test client |

## Stopping

Press `Ctrl+C` in the terminal running `run_server.sh` to stop all services.
